# Traditional Machine Learning Configuration
# Inherits from base_config.yaml

defaults:
  - /base_config
  - _self_

# Override base settings for traditional ML
experiment:
  type: "traditional_ml"
  name: "baseline_traditional"
  description: "Baseline traditional ML with hand-crafted features"

# Feature extraction settings
features:
  # Audio features to extract
  extract_features:
    - "mfcc"
    - "spectral_centroid"
    - "spectral_rolloff"
    - "spectral_bandwidth"
    - "zero_crossing_rate"
    # - "tempo"
    - "chroma"
    - "tonnetz"

  # MFCC settings
  mfcc:
    n_mfcc: 15
    n_fft: 4096
    hop_length: 512
    delta: true      
    delta2: true     

  # Spectral features
  spectral:
    n_fft: 4096
    hop_length: 512

  # Chroma features
  chroma:
    n_chroma: 12
    n_fft: 4096
    hop_length: 512

  # Tonnetz features
  tonnetz:
    n_fft: 2048
    hop_length: 512

# Feature preprocessing
preprocessing:
  # Aggregation methods for time-series features
  aggregation:
    methods: ["mean", "std", "min", "max", "median"]
    # methods: ["max", "std"]

  # Normalization
  normalization:
    method: "standard"  # standard, minmax, robust
    per_feature: true

  # Dimensionality reduction
  dimensionality_reduction:
    method: null  # pca, lda, null
    n_components: 0.95  # keep 95% variance for PCA
  
  silence_db_threshold: 30  # dB threshold for silence removal

# Model configurations
models:
  # K-Nearest Neighbors
  knn:
    n_neighbors: [5, 7, 10, 15, 30, 50]
    weights: ["uniform", "distance"]
    metric: ["euclidean", "manhattan", "cosine"]

  # Support Vector Machine
  svm:
    C: [1, 10.0, 100.0, 1000]
    kernel: [ "linear", "rbf", "poly"]
    gamma: ["scale", "auto", 0.001, 0.01, 0.1]

  # Random Forest
  random_forest:
    n_estimators: [100, 200, 300, 500, 800, 1000]
    max_depth: [10, 15, 20, 30, 50, null]
    min_samples_split: [2, 5, 10, 15, 20]
    min_samples_leaf: [1, 3, 5, 7, 9, 15, 20]

  # Gradient Boosting
  gradient_boosting:
    n_estimators: [100, 200, 300]
    learning_rate: [0.01, 0.1, 0.2]
    max_depth: [3, 5, 7]

  # Logistic Regression
  logistic_regression:
    C: [1.0, 10.0, 100.0]
    penalty: ["l1", "l2", "elasticnet"]
    solver: ["liblinear", "saga"]

# Cross-validation settings
cross_validation:
  method: "stratified_kfold"
  n_splits: 5
  shuffle: true

# Hyperparameter tuning
hyperparameter_tuning:
  method: "grid_search"  # grid_search, random_search, bayesian
  scoring: "accuracy"
  cv_folds: 3
  n_jobs: -1
  verbose: 1

# Training overrides for traditional ML
training:
  batch_size: null  # not applicable for traditional ML
  num_epochs: null  # not applicable for traditional ML
  learning_rate: null  # not applicable for traditional ML

